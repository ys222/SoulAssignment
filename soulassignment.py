# -*- coding: utf-8 -*-
"""SoulAssignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h2M7UZkGJUdNH5TfgjBidF8CSCXbSzSm
"""

# -------------------------------
# AI Safety Chatbot (Colab Deploy)
# -------------------------------

# Step 1: Install required packages
!pip install gradio transformers torch textblob

# Step 2: Imports and model initialization
import re
import json
from transformers import pipeline
from textblob import TextBlob
import gradio as gr
import os

# Load pretrained toxicity model
toxicity_detector = pipeline("text-classification", model="unitary/toxic-bert")

# Persistent conversation file
HISTORY_FILE = "conversation_history.json"

# Load conversation history if exists
if os.path.exists(HISTORY_FILE):
    with open(HISTORY_FILE, "r") as f:
        conversation_history = json.load(f)
else:
    conversation_history = []

# -------------------------------
# Step 3: Detection functions
# -------------------------------
def detect_abuse(message: str, threshold: float = 0.6):
    results = toxicity_detector(message)
    toxic_label = results[0]['label'].lower()
    toxic_score = results[0]['score']
    return (toxic_label == "toxic" and toxic_score > threshold), toxic_score

def detect_escalation(message: str, window: int = 5):
    global conversation_history
    conversation_history.append(message)
    if len(conversation_history) > window:
        conversation_history = conversation_history[-window:]
    sentiments = [TextBlob(m).sentiment.polarity for m in conversation_history]
    avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0
    if len(sentiments) > 2 and sentiments[-1] < -0.3 and sentiments[-1] < sentiments[-2]:
        return True, avg_sentiment
    return False, avg_sentiment

def detect_crisis(message: str):
    crisis_keywords = ["suicide", "kill myself", "can't go on", "end it", "worthless", "die"]
    return any(re.search(rf"\b{word}\b", message.lower()) for word in crisis_keywords)

def filter_content(message: str, user_age: int):
    adult_keywords = ["sex", "drugs", "violence", "gambling"]
    if user_age < 13:
        return any(re.search(rf"\b{word}\b", message.lower()) for word in adult_keywords)
    return False

# -------------------------------
# Step 4: Chatbot logic
# -------------------------------
def ai_safety_chat(user_msg, history, user_age=12):
    abuse, abuse_score = detect_abuse(user_msg)
    escalation, avg_sentiment = detect_escalation(user_msg)
    crisis = detect_crisis(user_msg)
    filtered = filter_content(user_msg, user_age)

    if crisis:
        response = "âš  Crisis detected! Escalating to human intervention."
    elif abuse:
        response = f"ğŸš¨ Abusive language detected (score={abuse_score:.2f})."
    elif escalation:
        response = f"âš¡ Escalation detected. Avg sentiment={avg_sentiment:.2f}"
    elif filtered:
        response = "ğŸ”’ Content blocked (age-inappropriate)."
    else:
        response = "âœ“ Safe message processed."

    # Append to history
    history.append((user_msg, response))

    # Save persistent conversation
    with open(HISTORY_FILE, "w") as f:
        json.dump([m[0] for m in history], f)

    return history, history

# -------------------------------
# Step 5: Gradio Interface
# -------------------------------
with gr.Blocks() as demo:
    user_age = gr.Number(value=12, label="User Age")
    chatbot_output = gr.Chatbot()
    user_input = gr.Textbox(placeholder="Type your message here...")

    # Load previous conversation
    if conversation_history:
        prev_history = [(msg, "âœ“ Previously processed") for msg in conversation_history]
        chatbot_output.value = prev_history

    def respond(message, history, age):
        return ai_safety_chat(message, history, user_age=age)

    user_input.submit(respond, inputs=[user_input, chatbot_output, user_age], outputs=[chatbot_output, chatbot_output])

# Launch with public URL
demo.launch(share=True)